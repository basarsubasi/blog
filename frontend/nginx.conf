# DNS resolver - using Google DNS with IPv4 only
resolver 8.8.8.8 8.8.4.4 valid=300s ipv6=off;
resolver_timeout 5s;

# Map to detect crawlers (must be outside server block)
map $http_user_agent $is_crawler {
    default 0;
    ~*facebookexternalhit 1;
    ~*Facebot 1;
    ~*Twitterbot 1;
    ~*LinkedInBot 1;
    ~*Slackbot 1;
    ~*TelegramBot 1;
    ~*WhatsApp 1;
    ~*SkypeUriPreview 1;
    ~*Discordbot 1;
}

server {
    
    listen 80;

    root /usr/share/nginx/html;
    index index.html;

    # Handle blog post requests
    location ~* ^/posts/(.+)$ {
        set $slug $1;
        
        # If it's a crawler, rewrite to internal location for proxying
        if ($is_crawler = 1) {
            rewrite ^/posts/(.+)$ /internal-meta-proxy/$1 last;
        }
        
        # For regular users, serve the React app
        try_files $uri $uri/ /index.html;
    }

    # Internal location for proxying to backend (crawlers only)
    location ~* ^/internal-meta-proxy/(.+)$ {
        internal;
        proxy_pass http://blogbackend.basarsubasi.com.tr/meta/posts/$1;
        proxy_set_header Host blogbackend.basarsubasi.com.tr;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header User-Agent $http_user_agent;
    }

    location / {
        try_files $uri $uri/ /index.html;
    }
}